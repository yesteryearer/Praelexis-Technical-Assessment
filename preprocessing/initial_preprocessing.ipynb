{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68712/2564353782.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from util.dataframe_utils import analyse_columns\n",
    "from util.datetime_utils import calculate_hour_sin_cos, fractional_hour\n",
    "\n",
    "df = pd.read_csv('../data/unprocessed/Tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've decided that I want to model the data based on the hour of the day, to establish certain probabilities that relate to various factors. This approach also allows for increasing complexity. Initially, I can do a simple linear regression, based on how likely a tweet is to appear a specific hour of the day. Thereafter, more compelx modeling can enter, such as what the probability is of a certain airline receiving a sentiment, or the type of negative sentiment a specific airline might receive.\n",
    "\n",
    "With this in mind, I will do some basic preprocessing to prepare the dataset for this modelling. Naturally, this will include some additional EDA as we explore how to transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's also rename the negative reason fields for consistency\n",
    "\n",
    "df = df.rename(columns={'negativereason': 'negative_reason', \n",
    "                        'negativereason_confidence': 'negative_reason_confidence'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Missing Ratio (%)</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airline_sentiment</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airline_sentiment_confidence</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative_reason</td>\n",
       "      <td>object</td>\n",
       "      <td>5462</td>\n",
       "      <td>37.31%</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative_reason_confidence</td>\n",
       "      <td>float64</td>\n",
       "      <td>4118</td>\n",
       "      <td>28.13%</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airline</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>airline_sentiment_gold</td>\n",
       "      <td>object</td>\n",
       "      <td>14600</td>\n",
       "      <td>99.73%</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>name</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>7701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negativereason_gold</td>\n",
       "      <td>object</td>\n",
       "      <td>14608</td>\n",
       "      <td>99.78%</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>retweet_count</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>text</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tweet_coord</td>\n",
       "      <td>object</td>\n",
       "      <td>13621</td>\n",
       "      <td>93.04%</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tweet_created</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tweet_location</td>\n",
       "      <td>object</td>\n",
       "      <td>4733</td>\n",
       "      <td>32.33%</td>\n",
       "      <td>3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>user_timezone</td>\n",
       "      <td>object</td>\n",
       "      <td>4820</td>\n",
       "      <td>32.92%</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Column Data Type  Missing Values Missing Ratio (%)  \\\n",
       "0                       tweet_id     int64               0             0.00%   \n",
       "1              airline_sentiment    object               0             0.00%   \n",
       "2   airline_sentiment_confidence   float64               0             0.00%   \n",
       "3                negative_reason    object            5462            37.31%   \n",
       "4     negative_reason_confidence   float64            4118            28.13%   \n",
       "5                        airline    object               0             0.00%   \n",
       "6         airline_sentiment_gold    object           14600            99.73%   \n",
       "7                           name    object               0             0.00%   \n",
       "8            negativereason_gold    object           14608            99.78%   \n",
       "9                  retweet_count     int64               0             0.00%   \n",
       "10                          text    object               0             0.00%   \n",
       "11                   tweet_coord    object           13621            93.04%   \n",
       "12                 tweet_created    object               0             0.00%   \n",
       "13                tweet_location    object            4733            32.33%   \n",
       "14                 user_timezone    object            4820            32.92%   \n",
       "\n",
       "    Unique Values  \n",
       "0           14485  \n",
       "1               3  \n",
       "2            1023  \n",
       "3              10  \n",
       "4            1410  \n",
       "5               6  \n",
       "6               3  \n",
       "7            7701  \n",
       "8              13  \n",
       "9              18  \n",
       "10          14427  \n",
       "11            832  \n",
       "12          14247  \n",
       "13           3081  \n",
       "14             85  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following columns were dropped entirely due to the large ratio of missing values\n",
    "\n",
    "df = df.drop(['airline_sentiment_gold', 'negativereason_gold', 'tweet_coord'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that there is a mismatch between the amount of missing values for the `negative_reasons` and `negative_reason_confidence`. Since there are more `negative_reasons_confidence` instances present than `negative_reason` instances, this implies that there must be some values attributed for confidence levels where no reasons are present. This might act as a guiding clue to how the original dataset handled missing values for `negative_reason_confidence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[pd.isnull(df['negative_reason']) & pd.notnull(df['negative_reason_confidence'])]\n",
    "\n",
    "non_missing_confidence_values = filtered_df['negative_reason_confidence']\n",
    "non_missing_confidence_values.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as expected, the dataset attribute 0% confidence to entries that are not present, we might follow suit in this convention, but first let's see if any entries that are associated with a negative reason, else it might lead to confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with a negative reason and 0% confidence: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filtered_df = df[pd.notnull(df['negative_reason']) & (df['negative_reason_confidence'] == 0)]\n",
    "filtered_df['negative_reason_confidence'].unique()\n",
    "\n",
    "print(f\"Number of entries with a negative reason and 0% confidence: {len(filtered_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill in all the missing values with 0 for the `negative_reason_confidence` field to indicate missing values. We'll keep track of these sort of changes in the `ENCODING.md` file found within the directory for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['negative_reason_confidence'] = df['negative_reason_confidence'].fillna(0)\n",
    "df['negative_reason_confidence'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Bad Flight', \"Can't Tell\", 'Late Flight',\n",
       "       'Customer Service Issue', 'Flight Booking Problems',\n",
       "       'Lost Luggage', 'Flight Attendant Complaints', 'Cancelled Flight',\n",
       "       'Damaged Luggage', 'longlines'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['negative_reason'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the inital EDA, it was established that there were no negative sentiments without a negative sentiment reason. Therefore, we can add a new category to the `negative_reason` called `Not Applicable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative_reason\n",
       "Not Applicable                 5462\n",
       "Customer Service Issue         2910\n",
       "Late Flight                    1665\n",
       "Can't Tell                     1190\n",
       "Cancelled Flight                847\n",
       "Lost Luggage                    724\n",
       "Bad Flight                      580\n",
       "Flight Booking Problems         529\n",
       "Flight Attendant Complaints     481\n",
       "longlines                       178\n",
       "Damaged Luggage                  74\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['negative_reason'] = df['negative_reason'].fillna('Not Applicable')\n",
    "df['negative_reason'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two columns that contain missing values that we have to deal with is the `tweet_location` and `user_timezone` fields. Since the Missing Ratio (%) is relatively high, I don't feel confident that imputation will provide an accurate reflection of the underlying patterns contained within the dataset. Nearly a third of the instances are missing! For now we'll assign the `Unknown` identifier to these fields. We are not spending too much time on this, because I won't be using these aspect for my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_timezone\n",
       "Unknown                       4820\n",
       "Eastern Time (US & Canada)    3744\n",
       "Central Time (US & Canada)    1931\n",
       "Pacific Time (US & Canada)    1208\n",
       "Quito                          738\n",
       "                              ... \n",
       "Warsaw                           1\n",
       "Irkutsk                          1\n",
       "Lisbon                           1\n",
       "Canberra                         1\n",
       "Newfoundland                     1\n",
       "Name: count, Length: 86, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_location'] = df['tweet_location'].fillna('Unknown')\n",
    "df['user_timezone'] = df['user_timezone'].fillna('Unknown')\n",
    "df['tweet_location'].value_counts()\n",
    "df['user_timezone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Missing Ratio (%)</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airline_sentiment</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airline_sentiment_confidence</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative_reason</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative_reason_confidence</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airline</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>name</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>7701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>retweet_count</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tweet_created</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tweet_location</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>3082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_timezone</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Column Data Type  Missing Values Missing Ratio (%)  \\\n",
       "0                       tweet_id     int64               0             0.00%   \n",
       "1              airline_sentiment    object               0             0.00%   \n",
       "2   airline_sentiment_confidence   float64               0             0.00%   \n",
       "3                negative_reason    object               0             0.00%   \n",
       "4     negative_reason_confidence   float64               0             0.00%   \n",
       "5                        airline    object               0             0.00%   \n",
       "6                           name    object               0             0.00%   \n",
       "7                  retweet_count     int64               0             0.00%   \n",
       "8                           text    object               0             0.00%   \n",
       "9                  tweet_created    object               0             0.00%   \n",
       "10                tweet_location    object               0             0.00%   \n",
       "11                 user_timezone    object               0             0.00%   \n",
       "\n",
       "    Unique Values  \n",
       "0           14485  \n",
       "1               3  \n",
       "2            1023  \n",
       "3              11  \n",
       "4            1410  \n",
       "5               6  \n",
       "6            7701  \n",
       "7              18  \n",
       "8           14427  \n",
       "9           14247  \n",
       "10           3082  \n",
       "11             86  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Encoding ##\n",
    "\n",
    "Let's encode the categorical features we are most inclined to use, namely `airline_sentiment`, `negative_reason`, and `airline`. Fields such as `tweet_id`, `name`, `text`, `tweet_location`, and `user_timezone` will be left untouched for now, as we might want them in their original forms. Certain parts of the data will have to manipulated based on the model, but currently we are engaged in a general data preproccesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'neutral', 1: 'positive', 2: 'negative'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# airline_sentiment\n",
    "\n",
    "codes, uniques = pd.factorize(df['airline_sentiment'])\n",
    "df['airline_sentiment'] = codes\n",
    "\n",
    "mapping = dict(enumerate(uniques))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Virgin America',\n",
       " 1: 'United',\n",
       " 2: 'Southwest',\n",
       " 3: 'Delta',\n",
       " 4: 'US Airways',\n",
       " 5: 'American'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# airline\n",
    "\n",
    "codes, uniques = pd.factorize(df['airline'])\n",
    "df['airline'] = codes\n",
    "\n",
    "mapping = dict(enumerate(uniques))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Not Applicable',\n",
       " 1: 'Bad Flight',\n",
       " 2: \"Can't Tell\",\n",
       " 3: 'Late Flight',\n",
       " 4: 'Customer Service Issue',\n",
       " 5: 'Flight Booking Problems',\n",
       " 6: 'Lost Luggage',\n",
       " 7: 'Flight Attendant Complaints',\n",
       " 8: 'Cancelled Flight',\n",
       " 9: 'Damaged Luggage',\n",
       " 10: 'longlines'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative_reason\n",
    "\n",
    "codes, uniques = pd.factorize(df['negative_reason'])\n",
    "df['negative_reason'] = codes\n",
    "\n",
    "mapping = dict(enumerate(uniques))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Missing Ratio (%)</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet_id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airline_sentiment</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airline_sentiment_confidence</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative_reason</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative_reason_confidence</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airline</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>name</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>7701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>retweet_count</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>text</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tweet_created</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>14247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tweet_location</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>3082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>user_timezone</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Column Data Type  Missing Values Missing Ratio (%)  \\\n",
       "0                       tweet_id     int64               0             0.00%   \n",
       "1              airline_sentiment     int64               0             0.00%   \n",
       "2   airline_sentiment_confidence   float64               0             0.00%   \n",
       "3                negative_reason     int64               0             0.00%   \n",
       "4     negative_reason_confidence   float64               0             0.00%   \n",
       "5                        airline     int64               0             0.00%   \n",
       "6                           name    object               0             0.00%   \n",
       "7                  retweet_count     int64               0             0.00%   \n",
       "8                           text    object               0             0.00%   \n",
       "9                  tweet_created    object               0             0.00%   \n",
       "10                tweet_location    object               0             0.00%   \n",
       "11                 user_timezone    object               0             0.00%   \n",
       "\n",
       "    Unique Values  \n",
       "0           14485  \n",
       "1               3  \n",
       "2            1023  \n",
       "3              11  \n",
       "4            1410  \n",
       "5               6  \n",
       "6            7701  \n",
       "7              18  \n",
       "8           14427  \n",
       "9           14247  \n",
       "10           3082  \n",
       "11             86  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Standardisation ##\n",
    "\n",
    "For the current iteration of the dataset, I won't scale or standardise anything. This can be done specific to the model. I think at this stage interprebility is of greater value. Each of the categorical features have a discrete number associated with them and are logged in `ENCODING.md`. The continous numerical fields such as `airline_sentiment_confidence` and `negative_reason_confidence` are already scale in range of `0-1`, which is an intuitive and interpreble when dealing with percentages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Temporal ##\n",
    "\n",
    "Since I've decided to model the data according to the time associated with the creation of a tweet, we can do some prelimanary preprocessing and feature engineering to accomodate the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'tweet_created' to datetime\n",
    "df['tweet_created'] = pd.to_datetime(df['tweet_created'])\n",
    "\n",
    "# The focus will be mostly on the hour per day that certain tweets happened, so let's extract these features\n",
    "\n",
    "df['day'] = df['tweet_created'].dt.day\n",
    "df['hour'] = df['tweet_created'].dt.hour\n",
    "df['minute'] = df['tweet_created'].dt.minute\n",
    "df['second'] = df['tweet_created'].dt.second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation of the hour of the day into sine and cosine values, and then back to the actual hour, is a method often used in feature engineering for cyclic or periodic features. This method is particularly useful in machine learning and data analysis contexts where the cyclical nature of certain variables (like time of day, day of week, month of year, etc.) needs to be captured effectively. I've defined utility functions for these purposes under the `util` module. This transformation method offers a good representation of the cyclical nature of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's make a fractional hour based on the associated minutes and seconds for a more precise temporal representation\n",
    "\n",
    "df['fractional_hour'] = df.apply(lambda row: fractional_hour(row['hour'], row['minute'], row['second']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's get our sine and cosine representations of the fractional hour\n",
    "\n",
    "df[['hour_sin', 'hour_cos']] = df['fractional_hour'].apply(lambda x: pd.Series(calculate_hour_sin_cos(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also going to drop the `day`, `hour`, `minute`, and `second`` information from the dataframe since information is contained within the `tweet_created` datetime column. This is so that the dataset doesn't become unnecessarily bloated and redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negative_reason</th>\n",
       "      <th>negative_reason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>fractional_hour</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52-08:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>11.597778</td>\n",
       "      <td>0.105107</td>\n",
       "      <td>-0.994461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59-08:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>11.266389</td>\n",
       "      <td>0.190880</td>\n",
       "      <td>-0.981613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2015-02-24 11:15:48-08:00</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>11.263333</td>\n",
       "      <td>0.191666</td>\n",
       "      <td>-0.981460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>0</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36-08:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>11.260000</td>\n",
       "      <td>0.192522</td>\n",
       "      <td>-0.981293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45-08:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>11.245833</td>\n",
       "      <td>0.196160</td>\n",
       "      <td>-0.980572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>569587686496825344</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>KristenReenders</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>2015-02-22 12:01:01-08:00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>12.016944</td>\n",
       "      <td>-0.004436</td>\n",
       "      <td>-0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>569587371693355008</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>itsropes</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>2015-02-22 11:59:46-08:00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11.996111</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>-0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>569587242672398336</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>sanyabun</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>2015-02-22 11:59:15-08:00</td>\n",
       "      <td>Nigeria,lagos</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11.987500</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>-0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>569587188687634433</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>5</td>\n",
       "      <td>SraJackson</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>2015-02-22 11:59:02-08:00</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>11.983889</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>-0.999991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>569587140490866689</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>daviddtwu</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>2015-02-22 11:58:51-08:00</td>\n",
       "      <td>dallas, TX</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11.980833</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>-0.999987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id  airline_sentiment  airline_sentiment_confidence  \\\n",
       "0      570306133677760513                  0                        1.0000   \n",
       "1      570301130888122368                  1                        0.3486   \n",
       "2      570301083672813571                  0                        0.6837   \n",
       "3      570301031407624196                  2                        1.0000   \n",
       "4      570300817074462722                  2                        1.0000   \n",
       "...                   ...                ...                           ...   \n",
       "14635  569587686496825344                  1                        0.3487   \n",
       "14636  569587371693355008                  2                        1.0000   \n",
       "14637  569587242672398336                  0                        1.0000   \n",
       "14638  569587188687634433                  2                        1.0000   \n",
       "14639  569587140490866689                  0                        0.6771   \n",
       "\n",
       "       negative_reason  negative_reason_confidence  airline             name  \\\n",
       "0                    0                      0.0000        0          cairdin   \n",
       "1                    0                      0.0000        0         jnardino   \n",
       "2                    0                      0.0000        0       yvonnalynn   \n",
       "3                    1                      0.7033        0         jnardino   \n",
       "4                    2                      1.0000        0         jnardino   \n",
       "...                ...                         ...      ...              ...   \n",
       "14635                0                      0.0000        5  KristenReenders   \n",
       "14636                4                      1.0000        5         itsropes   \n",
       "14637                0                      0.0000        5         sanyabun   \n",
       "14638                4                      0.6659        5       SraJackson   \n",
       "14639                0                      0.0000        5        daviddtwu   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "0                  0                @VirginAmerica What @dhepburn said.   \n",
       "1                  0  @VirginAmerica plus you've added commercials t...   \n",
       "2                  0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3                  0  @VirginAmerica it's really aggressive to blast...   \n",
       "4                  0  @VirginAmerica and it's a really big bad thing...   \n",
       "...              ...                                                ...   \n",
       "14635              0  @AmericanAir thank you we got on a different f...   \n",
       "14636              0  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637              0  @AmericanAir Please bring American Airlines to...   \n",
       "14638              0  @AmericanAir you have my money, you change my ...   \n",
       "14639              0  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "                  tweet_created tweet_location               user_timezone  \\\n",
       "0     2015-02-24 11:35:52-08:00        Unknown  Eastern Time (US & Canada)   \n",
       "1     2015-02-24 11:15:59-08:00        Unknown  Pacific Time (US & Canada)   \n",
       "2     2015-02-24 11:15:48-08:00      Lets Play  Central Time (US & Canada)   \n",
       "3     2015-02-24 11:15:36-08:00        Unknown  Pacific Time (US & Canada)   \n",
       "4     2015-02-24 11:14:45-08:00        Unknown  Pacific Time (US & Canada)   \n",
       "...                         ...            ...                         ...   \n",
       "14635 2015-02-22 12:01:01-08:00        Unknown                     Unknown   \n",
       "14636 2015-02-22 11:59:46-08:00          Texas                     Unknown   \n",
       "14637 2015-02-22 11:59:15-08:00  Nigeria,lagos                     Unknown   \n",
       "14638 2015-02-22 11:59:02-08:00     New Jersey  Eastern Time (US & Canada)   \n",
       "14639 2015-02-22 11:58:51-08:00     dallas, TX                     Unknown   \n",
       "\n",
       "       fractional_hour  hour_sin  hour_cos  \n",
       "0            11.597778  0.105107 -0.994461  \n",
       "1            11.266389  0.190880 -0.981613  \n",
       "2            11.263333  0.191666 -0.981460  \n",
       "3            11.260000  0.192522 -0.981293  \n",
       "4            11.245833  0.196160 -0.980572  \n",
       "...                ...       ...       ...  \n",
       "14635        12.016944 -0.004436 -0.999990  \n",
       "14636        11.996111  0.001018 -0.999999  \n",
       "14637        11.987500  0.003272 -0.999995  \n",
       "14638        11.983889  0.004218 -0.999991  \n",
       "14639        11.980833  0.005018 -0.999987  \n",
       "\n",
       "[14640 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['day', 'hour', 'minute', 'second'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the current purposes of my modeling the preprocessing will stop here. There is always a seemingly endless amount of EDA and preprocessing you can do, but the trade-off is time. In my view, the ideal is to be pragmatic.  So let's save the newly processed dataset and get to some modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/ProcessedTweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
